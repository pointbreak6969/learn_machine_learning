{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95cd6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90806861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating series\n",
    "s = pd.Series([1,3,5,7,9])\n",
    "print(s)\n",
    "# to give own indexing\n",
    "s = pd.Series(s, index=['a','b','c','d','e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe \n",
    "data = {\n",
    "    \"Name\" : [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Age\" : [24, 27, 22, 32],\n",
    "    \"City\" : [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\"],\n",
    "    \"Maths\" : [85, 90, 78, 92],\n",
    "    \"Science\" : [88, 92, 80, 95],\n",
    "    \"English\" : [90, 85, 88, 91]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# to give own indexing\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'd'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know basic info about dataframe\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Age\", \"Maths\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "# Creating a new column 'Total' which is the sum of 'Maths', 'Science', and 'English'\n",
    "df['Total'] = df['Maths'] + df['Science'] + df['English']\n",
    "print(df)\n",
    "# Adding a percentage column\n",
    "df[\"Percentage\"] = ((df['Maths'] + df['Science'] + df['English']) / 300) * 100\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3bef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "employees = pd.DataFrame({\n",
    "    \"Name\": [\"John\", \"Sarah\", \"Michael\", \"Emily\", \"David\", \"Jessica\", \"Daniel\", \"Lisa\", \"Matthew\", \"Amanda\"],\n",
    "    \"Age\": [28, 35, 42, 29, 38, 31, 45, 27, 33, 40],\n",
    "    \"Department\": [\"IT\", \"HR\", \"Finance\", \"IT\", \"Marketing\", \"HR\", \"Finance\", \"Marketing\", \"IT\", \"Finance\"],\n",
    "    \"Salary\": [65000, 72000, 85000, 68000, 75000, 70000, 90000, 62000, 78000, 88000],\n",
    "    \"Experience\": [3, 8, 15, 4, 10, 6, 18, 2, 7, 12]\n",
    "})\n",
    "print(employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db4d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc[]: label based indexing\n",
    "print(employees.loc[2:6, [\"Name\", \"Age\", \"Department\"] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc[] : integer based indexing\n",
    "print(employees.iloc[:2, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean based indexing\n",
    "condition = employees[\"Age\"] > 30\n",
    "print(employees[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac417348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query based indexing\n",
    "print(employees.query(\"Age > 40 and Salary>70000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5048f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with missing data\n",
    "missing_data_df = pd.DataFrame({\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\"],\n",
    "    \"Age\": [25, None, 30, 28, None, 35],\n",
    "    \"Salary\": [50000, 60000, None, 55000, 62000, None],\n",
    "    \"Department\": [\"IT\", \"HR\", None, \"Finance\", \"IT\", \"Marketing\"],\n",
    "    \"Experience\": [2, 5, 7, None, 4, 10]\n",
    "})\n",
    "print(\"\\nMissing values count:\")\n",
    "print(missing_data_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01856488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting missing values\n",
    "# this is to drop columns with any missing values\n",
    "cleaned_df = missing_data_df.dropna(axis=1) \n",
    " # this is to drop rows with any missing values\n",
    "cleaned_df = missing_data_df.dropna()\n",
    "# this is to change actual dataframe\n",
    "missing_data_df.dropna(inplace=True)\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the value\n",
    "# filled_value =missing_data_df.fillna(0)\n",
    "value = missing_data_df[\"Age\"].mean() # we can use mode(), median() also\n",
    "print(value)\n",
    "missing_data_df[\"Age1\"] = missing_data_df[\"Age\"].fillna(value)\n",
    "print(missing_data_df)\n",
    "# print(filled_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill and backward fill. we generally use both forward and backward fill together to fill missing values as some may not be filled by only one method.\n",
    "forward_filled_df = missing_data_df.ffill() # this fills the missing value with previous value\n",
    "backward_filled_df = missing_data_df.bfill() # this fills the missing value with next value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c00dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove duplicate values\n",
    "data_with_duplicates = pd.DataFrame({\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Alice\", \"Eve\", \"Bob\"],\n",
    "    \"Age\": [25, 30, 30, 25, 28, 30],\n",
    "    \"Salary\": [50000, 60000, 60000, 50000, 62000, 60000]\n",
    "})\n",
    "print(\"\\nDataFrame with duplicates:\")\n",
    "print(data_with_duplicates)\n",
    "df_no_duplicates = data_with_duplicates.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame with duplicated values for practice\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'David'],\n",
    "    'Age': [25, 30, 35, 25, 30, 40],\n",
    "    'City': ['NYC', 'LA', 'Chicago', 'NYC', 'LA', 'Houston']\n",
    "}\n",
    "\n",
    "duplicated_data = pd.DataFrame(data)\n",
    "print(duplicated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if there are any duplicates\n",
    "print(duplicated_data.duplicated().sum())\n",
    "\n",
    "# to check duplicated data in column \n",
    "print(duplicated_data[[\"Name\", \"City\"]].duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to delete duplicated data\n",
    "new_duplicated_data =duplicated_data.drop_duplicates()\n",
    "new_duplicated_data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove outliner we use IQR method\n",
    "# Create a DataFrame with outliers\n",
    "outlier_df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace'],\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 200],  # 200 is an outlier\n",
    "    'Salary': [50000, 60000, 70000, 80000, 90000, 100000, 5000000]  # 5000000 is an outlier\n",
    "})\n",
    "\n",
    "# Calculate Q1, Q3, and IQR for Age and Salary\n",
    "Q1_age = outlier_df['Age'].quantile(0.25)\n",
    "Q3_age = outlier_df['Age'].quantile(0.75)\n",
    "IQR_age = Q3_age - Q1_age\n",
    "\n",
    "Q1_salary = outlier_df['Salary'].quantile(0.25)\n",
    "Q3_salary = outlier_df['Salary'].quantile(0.75)\n",
    "IQR_salary = Q3_salary - Q1_salary\n",
    "\n",
    "# Define bounds\n",
    "lower_bound_age = Q1_age - 1.5 * IQR_age\n",
    "upper_bound_age = Q3_age + 1.5 * IQR_age\n",
    "\n",
    "lower_bound_salary = Q1_salary - 1.5 * IQR_salary\n",
    "upper_bound_salary = Q3_salary + 1.5 * IQR_salary\n",
    "\n",
    "# Filter out outliers\n",
    "outlier_df_cleaned = outlier_df[\n",
    "    (outlier_df['Age'] >= lower_bound_age) & (outlier_df['Age'] <= upper_bound_age) &\n",
    "    (outlier_df['Salary'] >= lower_bound_salary) & (outlier_df['Salary'] <= upper_bound_salary)\n",
    "]\n",
    "\n",
    "print(outlier_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23052df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for testing data aggregation and grouping\n",
    "agg_df = pd.DataFrame({\n",
    "    'Department': ['HR', 'IT', 'HR', 'Finance', 'IT', 'Finance', 'HR', 'IT'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry'],\n",
    "    'Salary': [50000, 60000, 55000, 70000, 65000, 75000, 52000, 68000],\n",
    "    'Years': [2, 3, 4, 5, 2, 6, 3, 4]\n",
    "})\n",
    "print(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "department = agg_df.groupby(\"Department\")[\"Salary\"].sum().reset_index()\n",
    "department\n",
    "# groupby multiple columns\n",
    "dept_years = agg_df.groupby([\"Department\", \"Years\"])[\"Salary\"].mean().reset_index()\n",
    "dept_years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8844ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggegration\n",
    "agg_value = agg_df.groupby(\"Department\")[\"Salary\"].agg([\"sum\", \"mean\", \"max\", \"min\"])\n",
    "\n",
    "#different aggregations for different columns\n",
    "agg_value1 = agg_df.groupby(\"Department\").agg({\n",
    "    \"Salary\" : [\"mean\", \"median\", \"max\"],\n",
    "    \"Years\" : \"max\"\n",
    "})\n",
    "agg_value1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table\n",
    "pivot_table = agg_df.pivot_table(\n",
    "    values = [\"Salary\"], \n",
    "    columns=[\"Department\"],\n",
    "    index= \"Employee\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ")\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b399117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging and Joining DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'EmployeeID': [1, 2, 3, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "    'Employee': [3, 4, 5, 6],\n",
    "    'Department': ['HR', 'IT', 'Finance', 'Marketing']\n",
    "})\n",
    "\n",
    "# innerjoin \n",
    "# inner join returns only the rows with matching keys in both DataFrames.\n",
    "# outer join returns all rows from both DataFrames, filling in NaNs for missing matches on either side.\n",
    "# innerdf = pd.merge(df1, df2, how=\"outer\")  # for this to work there should be matching column in both dataframes\n",
    "innerdf = pd.merge(df1, df2, left_on=\"EmployeeID\", right_on=\"Employee\", how=\"inner\")\n",
    "print(innerdf)\n",
    "outer_df = pd.merge(df1, df2, left_on=\"EmployeeID\", right_on=\"Employee\", how=\"outer\")\n",
    "print(outer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e02dbe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID     Name  Employee Department\n",
      "0           1    Alice       NaN        NaN\n",
      "1           2      Bob       NaN        NaN\n",
      "2           3  Charlie       3.0         HR\n",
      "3           4    David       4.0         IT\n",
      "   EmployeeID     Name  Employee Department\n",
      "0         3.0  Charlie         3         HR\n",
      "1         4.0    David         4         IT\n",
      "2         NaN      NaN         5    Finance\n",
      "3         NaN      NaN         6  Marketing\n"
     ]
    }
   ],
   "source": [
    "# left and right join\n",
    "#left join works on all rows from left dataframe and matching rows from right dataframe\n",
    "left_df = pd.merge(df1, df2, how=\"left\", left_on=\"EmployeeID\", right_on=\"Employee\")\n",
    "print(left_df)\n",
    "# right join works on all rows from right dataframe and matching rows from left dataframe\n",
    "right_df = pd.merge(df1, df2, how=\"right\", left_on=\"EmployeeID\", right_on=\"Employee\")\n",
    "print(right_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac015a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID     Name\n",
      "0           1    Alice\n",
      "1           2      Bob\n",
      "2           3  Charlie\n",
      "3           4    David\n",
      "4           5      Eve\n",
      "5           6    Frank\n",
      "   EmployeeID     Name  Employee Department\n",
      "0           1    Alice         3         HR\n",
      "1           2      Bob         4         IT\n",
      "2           3  Charlie         5    Finance\n",
      "3           4    David         6  Marketing\n"
     ]
    }
   ],
   "source": [
    "# concatenation\n",
    "df3 = pd.DataFrame({    \n",
    "    'EmployeeID': [5, 6],\n",
    "    'Name': ['Eve', 'Frank']\n",
    "})\n",
    "combined_df = pd.concat([df1, df3], ignore_index=True) # ignore index to reset the index in the combined dataframe\n",
    "print(combined_df)\n",
    "horizontal_df = pd.concat([df1, df2], axis=1) # axis=1 for horizontal concatenation\n",
    "print(horizontal_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
